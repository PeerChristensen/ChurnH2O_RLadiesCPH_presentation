---
title: "Churn Prediction with H2O AutoML"
author: "Peer Christensen"
date: "2019-12-05"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=F,message=F,cache=F)
```

class: inverse, center, middle

# EDA

---

```{r}
library(tidyverse)
```

```{r echo = F}

df <- read_csv("new_churn_training.csv") %>%
  mutate(Perm_anyperm = factor(Perm_anyperm),
         Churned30 = factor(Churned30),
       Perm_recommendations = factor(Perm_recommendations),
       Perm_newsletter = factor(Perm_newsletter),
       MatasUser = factor(MatasUser),
       CoopUser = factor(CoopUser)) %>%
  mutate_if(is.character,factor) %>%
  select(-IsFree,-PremiumEbookRatio) %>%
  drop_na() %>%
  filter(DaysSinceLatestSignup > 30) 

# Store the identifier for later
Customer_Key <- df$Customer_Key

df <- df %>% select(-Customer_Key)
```

```{r}
dim(df)
```


### Checking for target class (im)balance

```{r}
table(df$Churned30)
           
round(prop.table(table(df$Churned30)),3)*100
```

---

```{r}
names(df[1:50])
```

---

## Correlation funnel

```{r}
library(correlationfunnel)

df_binned <- df %>%
  select(-DateStatus) %>%
  binarize(n_bins = 5, thresh_infreq = 0.01, name_infreq = "OTHER", one_hot = TRUE)

df_churn_corr <- df_binned %>%
  correlate(Churned30__1)

```

---

```{r}
df_churn_corr %>%
  plot_correlation_funnel()
```

---

```{r}
df_churn_corr %>%
  arrange(desc(correlation)) %>%
  top_n(15) %>%
  plot_correlation_funnel()
```

---

## Plotting Churn against the best predictors

```{r}
red   <- "#c51924"
blue  <- "#028ccc"

top_features <- df_churn_corr %>%
  top_n(15) %>%
  filter(feature != "Churned30") %>%
  pull(feature) %>% 
  as.vector()

numeric_features <- df %>%
  select(top_features) %>%
  select_if(is.numeric) %>% 
  names()

categorical_features <- df %>%
  select(top_features) %>%
  select_if(is.factor) %>% 
  names()
```

---

## Churn ~ Numeric variables

```{r}
p1 <- df %>%
  select(Churned30,numeric_features) %>%
  gather(variable, value,-Churned30) %>%
  ggplot(aes(x=value, fill = Churned30,colour=Churned30)) +
  facet_wrap(~variable,scales="free",ncol=3) +
  geom_density(alpha = 0.5) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1),
        legend.position = "top",
        legend.text = element_text(size=18),
        legend.title = element_text(size=18)) +
  scale_fill_manual(values=c(red,blue)) +
  scale_colour_manual(values=c(red,blue))
```
---
```{r}
p1
```

---

## Churn ~ Categorical variables

```{r}
p2 <- df %>%
  select(Churned30,categorical_features) %>%
  gather(variable, value,-Churned30) %>%
  mutate(value = ifelse(is.na(value),"na",value)) %>%
  count(Churned30, variable, value) %>%
  ggplot(aes(x = reorder(value,-n), y = n, fill = Churned30, color = Churned30)) +
  facet_wrap(~ variable, ncol = 3, scales = "free") +
  geom_bar(stat = "identity", alpha = 0.5) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "top",
        legend.text = element_text(size=18),
        legend.title = element_text(size=18)) +
  scale_fill_manual(values=c(red,blue)) +
  scale_colour_manual(values=c(red,blue))
```
---
```{r}
p2
```

---

class: inverse, center, middle

# Feature engineering

---

### Calculate order size

```{r}
df$AverageOrderSize <- df$TotalNetRevenue / df$TotalOrderCount
```

### Signup month

```{r}
library(lubridate)

# Get the current date
today <- max(as.Date(df$DateStatus)) 

# Get the signup date
DateLatestSignup <- today - days(df$DaysSinceLatestSignup)

# Find the signup month
df$DateLatestSignup_month <- month(DateLatestSignup)

df <- df %>% select(-DateStatus)
```

---

## Ratio of literary preferences

```{r}
f_lit_mean <- df %>% 
  select(starts_with("F0")) %>%
  transmute(m = rowMeans(.)) %>%
  pull(m)

s_lit_mean <- df %>% 
  select(starts_with("S0")) %>%
  transmute(m = rowMeans(.))  %>%
  pull(m)

f_ratio <- f_lit_mean / (s_lit_mean +f_lit_mean)
```

---

## Principal components

```{r}
s_lit_vars <- df %>% 
  select(starts_with("S0")) %>%
           names()

f_lit_vars <- df %>% 
  select(starts_with("F0")) %>%
  names()

pca_s <- prcomp(df[s_lit_vars], scale = FALSE) 
pca_f <- prcomp(df[f_lit_vars], scale = FALSE)

df <- df %>%
  mutate(
    pc_s1 = pca_s$x[,1],
    pc_s2 = pca_s$x[,2],
    pc_f1 = pca_f$x[,1],
    pc_f2 = pca_f$x[,2]
  )

#remove original f-s variables
df <- df %>%
  select(-f_lit_vars,-s_lit_vars)
```

---

class: inverse, center, middle

# Data partitioning

---

```{r}
library(caret)

df$Customer_Key <- as.character(Customer_Key)

set.seed(42)
index <- createDataPartition(df$Churned30, p = 0.7, list = FALSE)

train_data <- df[ index, ]
test_data  <- df[-index, ]

Customer_Key_train <- train_data$Customer_Key
Customer_Key_test <- test_data$Customer_Key

train_data <- train_data %>% select(-Customer_Key)
test_data  <- test_data  %>% select(-Customer_Key)
```

---

class: inverse, center, middle

# Preprocessing

---

```{r}
library(recipes)

recipe_churn <- recipe(Churned30 ~ ., train_data) %>%
  step_nzv(all_numeric(), -all_outcomes()) %>%
  step_YeoJohnson(all_numeric(), -all_outcomes()) %>%
  step_corr(all_numeric(), -all_outcomes()) %>%
  step_center(all_numeric(), -all_outcomes()) %>%
  step_scale(all_numeric(), -all_outcomes()) %>%
  prep(data = train_data)

train_data <- bake(recipe_churn, new_data = train_data) %>%
  select(Churned30, everything())

test_data <- bake(recipe_churn, new_data = test_data) %>%
  select(Churned30, everything())

train_data$Customer_Key <- Customer_Key_train
test_data$Customer_Key <- Customer_Key_test

# save recipe
saveRDS(recipe_churn,"recipe_preprocess.rds")


```

---

class: inverse, center, middle

# Training with H2O!

---

```{r}
library(h2o)

h2o.init(nthreads = -1)

h2o.no_progress()
```

---

```{r}
train_hf <- as.h2o(train_data)
test_hf <- as.h2o(test_data)

response <- "Churned30"
features <- setdiff(colnames(train_hf), response)

train_hf[, response] <- as.factor(train_hf[, response])
test_hf[, response]  <- as.factor(test_hf[, response])
```

---

```{r echo = F}
aml <- h2o.automl(x = features, 
                  y = response,
                  training_frame   = train_hf,
                  balance_classes  = TRUE,
                  max_runtime_secs = 60*1,
                  nfolds = 10)
```

```{r eval = F}
aml <- h2o.automl(x = features, 
                  y = response,
                  training_frame   = train_hf,
                  balance_classes  = TRUE,
                  max_runtime_secs = 3600*5,
                  nfolds = 10)
```

---

### Save all models

```{r eval = F}
for (i in 1:nrow(aml@leaderboard)) {

  aml_model = h2o.getModel(aml@leaderboard[i, 1])
  h2o.saveModel(object = aml_model, "models10")
}
```